<div align="center">

```
 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â•šâ•â•â–ˆâ–ˆâ•”â•â•â•
â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   
â–ˆâ–ˆâ•‘â–„â–„ â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   
â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   
 â•šâ•â•â–€â–€â•â•  â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â• â•šâ•â•   â•šâ•â•  
```

**dual-arm desk robot Â· expressive LED eyes Â· open-source Python brain**

[![built by @0xaiwhisperer](https://img.shields.io/badge/built%20by-%400xaiwhisperer-00f5c4?style=flat-square&labelColor=0a0a0a)](https://twitter.com/0xaiwhisperer)
[![platform](https://img.shields.io/badge/platform-Raspberry%20Pi%205-c51a4a?style=flat-square&labelColor=0a0a0a)](https://www.raspberrypi.com/)
[![license](https://img.shields.io/badge/license-MIT-ffffff?style=flat-square&labelColor=0a0a0a)](LICENSE)
[![open source](https://img.shields.io/badge/open-source-00f5c4?style=flat-square&labelColor=0a0a0a)](#)

</div>

---

<img src="assets/thumbnail.JPG" alt="Qubit Desk Robot" width="100%" />

---

## what is qubit?

Qubit is a fully functional **dual-arm desktop robot** built for demos, livestreams, and content creation. Two SO-100 arms. Expressive 16Ã—16 LED eyes. Ambient RGB lighting. A Raspberry Pi brain. And a Python codebase that makes it all scriptable, remixable, and yours.

This isn't a toy â€” it's a platform. Bimanual manipulation, teleoperation, computer vision, idle animations, a web dashboard â€” all open source, all hackable.

> *machines, memes, and magic* â€” [@0xaiwhisperer](https://twitter.com/0xaiwhisperer)

---

## in action

<table>
  <tr>
    <td align="center" width="50%">
      <img src="assets/pickup_screwdriver.gif" width="100%" alt="Qubit picks up a screwdriver" /><br/>
      <sub><b>precision pick & place</b> â€” screwdriver grab sequence</sub>
    </td>
    <td align="center" width="50%">
      <img src="assets/robot_dance.gif" width="100%" alt="Qubit doing a robot dance" /><br/>
      <sub><b>robot dance</b> â€” synchronized bimanual choreography</sub>
    </td>
  </tr>
</table>

---

## capabilities

| feature | details |
|---|---|
| ğŸ¦¾ **bimanual arms** | 2Ã— SO-100 arms Â· 12Ã— STS3215 servos Â· independent control |
| ğŸ‘ï¸ **expressive face** | 16Ã—16 iDotMatrix LED Â· 14 included emotes Â· fully custom |
| ğŸ’¡ **ambient lighting** | dual WS2812B LED tubes Â· full RGB Â· programmable effects |
| ğŸ§  **Pi 5 brain** | Raspberry Pi 5 Â· Python 3.10+ Â· modular script library |
| ğŸ® **teleoperation** | leader/follower arm pairing via LeRobot |
| ğŸ“· **camera vision** | face tracking Â· Pi Camera Module v3 |
| ğŸŒ **web dashboard** | local control UI at `qubit.local:5000` |

---

## ğŸ“‹ table of contents

- [Hardware & BOM](#hardware)
- [3D Printing](#3d-printing)
- [Software Setup](#software-setup)
- [Python Scripts](#python-scripts)
- [Emotes & LED Animations](#emotes--led-animations)
- [Project Structure](#project-structure)
- [Troubleshooting](#troubleshooting)
- [Contributing](#contributing)

---

## hardware

### bill of materials â€” per SO-100 arm

> Each Qubit uses **2Ã— SO-100 arms** â€” multiply arm quantities by 2. The optional SO-101 leader arm (teleoperation) needs 6Ã— STS3215 in a specific mix: 3Ã— C046, 2Ã— C044, 1Ã— C001 â€” available as a bundle on Alibaba.

| part | qty | ğŸ‡ºğŸ‡¸ USD | ğŸ‡ºğŸ‡¸ link | ğŸ‡ªğŸ‡º EUR | ğŸ‡ªğŸ‡º link | ğŸ‡¨ğŸ‡³ RMB | ğŸ‡¨ğŸ‡³ link |
|---|:---:|---:|---|---:|---|---:|---|
| STS3215 Servo (C001, 1/345 gear) | 6 | $14 | [Alibaba](https://www.alibaba.com/product-detail/Top-Seller-Low-Cost-Feetech-STS3215_1600999461525.html) | â‚¬13 | [Alibaba](https://www.alibaba.com/product-detail/Top-Seller-Low-Cost-Feetech-STS3215_1600999461525.html) | ï¿¥97.72 | [TaoBao](https://item.taobao.com/item.htm?id=712179366565) |
| Motor Control Board | 1 | $11 | [Amazon](https://www.amazon.com/Waveshare-Integrates-Control-Circuit-Supports/dp/B0CTMM4LWK/) | â‚¬12 | [Amazon](https://www.amazon.fr/-/en/dp/B0CJ6TP3TP/) | ï¿¥27 | [TaoBao](https://detail.tmall.com/item.htm?id=738817173460) |
| USB-C Cable 2-pack | 1 | $7 | [Amazon](https://www.amazon.com/Charging-etguuds-Charger-Braided-Compatible/dp/B0B8NWLLW2/) | â‚¬7 | [Amazon](https://www.amazon.fr/dp/B07BNF842T/) | ï¿¥23.90 | [TaoBao](https://detail.tmall.com/item.htm?id=44425281296) |
| Power Supply (7.5V DC) | 1 | $10 | [Amazon](https://www.amazon.com/Facmogu-Switching-Transformer-Compatible-5-5x2-1mm/dp/B087LY41PV/) | â‚¬13 | [Amazon](https://www.amazon.fr/-/en/dp/B01HRR9GY4/) | ï¿¥22.31 | [TaoBao](https://item.taobao.com/item.htm?id=544824248494) |
| Table Clamp 2-pack | 1 | $5 | [Amazon](https://www.amazon.com/Mr-Pen-Carpenter-Clamp-6inch/dp/B092L925J4/) | â‚¬8 | [Amazon](https://www.amazon.fr/-/en/dp/B08HZ1QRBF/) | ï¿¥7.80 | [TaoBao](https://detail.tmall.com/item.htm?id=738636473238) |
| Screwdriver Set | 1 | $6 | [Amazon](https://www.amazon.com/Precision-Phillips-Screwdriver-Electronics-Computer/dp/B0DB227RTH) | â‚¬10 | [Amazon](https://www.amazon.fr/dp/B08ZXVMVYD/) | ï¿¥14.90 | [TaoBao](https://detail.tmall.com/item.htm?id=675684600845) |
| **per arm** | | **$123** | | **â‚¬128** | | **ï¿¥682** | |
| **2 arms total** | | **$246** | | **â‚¬256** | | **ï¿¥1,364** | |

> âš ï¸ Verify gear ratios before ordering â€” the follower arm uses **all 1/345 (C001)**. Power supply must output **7.4â€“7.5V DC at 5A minimum** per arm.

---

### full system BOM

| component | notes | est. cost |
|---|---|---:|
| **Raspberry Pi 5** (4GB or 8GB) | main compute | ~$60â€“$80 |
| **16Ã—16 LED Matrix** | iDotMatrix, BLE-controlled | ~$20â€“$35 |
| **LED Tubes** Ã—2 | WS2812B addressable RGB, 30â€“60cm | ~$15â€“$25 |
| **Bambu Lab A1** | prints all structural parts | ~$299 |
| **MicroSD Card** 32GB+ | Raspberry Pi OS | ~$10 |
| **Powered USB Hub** 4-port | connects both arm boards | ~$15 |
| **Pi Camera Module v3** | optional Â· face tracking | ~$25 |
| **5V/5A USB-C PSU** | for Raspberry Pi 5 | ~$12 |

> **ğŸ’° estimated full build (US):** ~$700â€“$800 depending on sourcing

---

### wiring diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  RASPBERRY PI 5                 â”‚
â”‚                                                 â”‚
â”‚  USB-A â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Motor Board (Left Arm)       â”‚
â”‚  USB-A â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Motor Board (Right Arm)      â”‚
â”‚  USB-C (power) â—„â”€â”€ 5V/5A Supply                â”‚
â”‚  GPIO / BLE â”€â”€â”€â”€â”€â–º 16Ã—16 LED Matrix             â”‚
â”‚  GPIO PWM â”€â”€â”€â”€â”€â”€â”€â–º LED Tube Left (WS2812B)      â”‚
â”‚  GPIO PWM â”€â”€â”€â”€â”€â”€â”€â–º LED Tube Right (WS2812B)     â”‚
â”‚  CSI / USB â”€â”€â”€â”€â”€â”€â–º Pi Camera (optional)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Motor Board Ã—2 (one per arm)
  â”œâ”€â”€ USB-C â—„â”€â”€ 7.5V DC Power Supply (dedicated per arm)
  â””â”€â”€ Serial bus â”€â”€â–º 6Ã— STS3215 Servos (daisy-chained)
```

> âš ï¸ **Never power servo boards from the Pi's USB ports.** Always use a dedicated supply to avoid brownouts and servo damage.

---

## 3D printing

All structural parts are designed for a **Bambu Lab A1** in PLA+ or PETG.

**recommended settings:**
- Layer height: `0.2mm`
- Infill: `40%` Gyroid
- Supports: required for arm joint brackets
- Print time per arm: ~8â€“12 hours

| file | description | material |
|---|---|---|
| `qubit_head_shell.stl` | main head enclosure Â· LED matrix housing | PLA+ |
| `qubit_head_back.stl` | rear panel with cable routing | PLA+ |
| `qubit_neck_bracket.stl` | neck-to-body mount | PETG |
| `qubit_body_frame.stl` | central torso Â· electronics mount | PETG |
| `qubit_led_tube_mount_left.stl` | left LED tube arm mount | PLA+ |
| `qubit_led_tube_mount_right.stl` | right LED tube arm mount | PLA+ |
| `qubit_arm_shoulder_left.stl` | left SO-100 shoulder attachment | PETG |
| `qubit_arm_shoulder_right.stl` | right SO-100 shoulder attachment | PETG |
| `qubit_base_plate.stl` | weighted desk base | PETG |
| `qubit_cable_cover.stl` | rear cable management cover | PLA+ |

> ğŸ’¡ Print body frame and shoulder brackets in PETG â€” they take the most torque stress. PLA+ is fine for cosmetic shells.

---

## software setup

### prerequisites

- Raspberry Pi OS Bookworm 64-bit â€” [download](https://www.raspberrypi.com/software/)
- Python 3.10+
- Git

### installation

```bash
# clone
git clone https://github.com/0xaiwhisperer/qubit.git
cd qubit

# virtual environment
python3 -m venv .venv
source .venv/bin/activate

# dependencies
pip install -r requirements.txt

# optional: teleoperation support
pip install lerobot
```

### configuration

```bash
cp config/config.example.yaml config/config.yaml
nano config/config.yaml
```

```yaml
arms:
  left:
    port: /dev/ttyUSB0
    servo_ids: [1, 2, 3, 4, 5, 6]
  right:
    port: /dev/ttyUSB1
    servo_ids: [7, 8, 9, 10, 11, 12]

led_matrix:
  type: idotmatrix
  size: 16
  connection: bluetooth
  mac_address: "AA:BB:CC:DD:EE:FF"  # â† replace this

led_tubes:
  left_pin: 18
  right_pin: 19
  num_pixels: 30

camera:
  enabled: false
  device: 0
  resolution: [640, 480]
```

Find your serial ports: `ls /dev/ttyUSB*` â€” plug/unplug each arm to map them.

---

## python scripts

| script | description | usage |
|---|---|---|
| `run_arm.py` | manual servo control via keyboard or gamepad | `--arm left` |
| `teleop.py` | mirror leader arm â†’ follower arm | â€” |
| `record_demo.py` | record arm movement sequence to JSON | `--arm left --output demos/wave.json` |
| `play_demo.py` | replay a recorded sequence | `--file demos/wave.json` |
| `calibrate.py` | interactive servo calibration wizard | `--arm left` |
| `led_matrix.py` | push emotes/animations to LED matrix | `--emote happy` |
| `led_tubes.py` | RGB tube lighting effects | `--mode pulse --color 00f5c4` |
| `face_track.py` | face tracking + arm movement via camera | â€” |
| `idle_behavior.py` | ambient idle animations | â€” |
| `diagnostics.py` | servo health Â· temps Â· load | `--arm all` |
| `dashboard.py` | local web control dashboard | â†’ `qubit.local:5000` |

### example workflows

```bash
# autostart idle loop on boot
python /home/pi/qubit/scripts/idle_behavior.py &

# record and replay a wave
python scripts/record_demo.py --arm right --output demos/wave.json
# [ physically move the arm to record ]
python scripts/play_demo.py --file demos/wave.json --loop 3

# launch web dashboard
python scripts/dashboard.py
# â†’ open http://qubit.local:5000
```

---

## emotes & LED animations

All emotes live in `/emotes` as JSON files â€” each describes a 16Ã—16 pixel frame sequence for the LED matrix.

### emote format

```json
{
  "name": "happy",
  "fps": 8,
  "loop": true,
  "frames": [
    {
      "pixels": [
        [0,0,0, ...],  // row 0: 16 RGB values
        [0,0,0, ...],  // row 1
        ...            // rows 2â€“15
      ]
    }
  ]
}
```

### included emotes

| file | expression | animated |
|---|---|:---:|
| `happy.json` | ğŸ˜Š happy eyes | âœ… |
| `blink.json` | ğŸ˜ slow blink | âœ… |
| `sad.json` | ğŸ˜¢ sad eyes | âœ… |
| `angry.json` | ğŸ˜  angry brow | âœ… |
| `surprised.json` | ğŸ˜² wide eyes | âœ… |
| `wink.json` | ğŸ˜‰ left eye wink | âœ… |
| `sleep.json` | ğŸ˜´ closed eyes + zzz | âœ… |
| `loading.json` | ğŸ”„ spinning loader | âœ… |
| `startup.json` | ğŸ’¡ boot sequence flash | âœ… |
| `eye_track_left.json` | ğŸ‘€ eyes shift left | âœ… |
| `eye_track_right.json` | ğŸ‘€ eyes shift right | âœ… |
| `heart.json` | â¤ï¸ heart pulse | âœ… |
| `glitch.json` | âš¡ glitch effect | âœ… |
| `off.json` | â¬› all pixels off | â€” |

### playing emotes

```bash
# single emote
python scripts/led_matrix.py --emote happy

# sequence
python scripts/led_matrix.py --sequence startup,happy,blink

# loop indefinitely
python scripts/led_matrix.py --emote sleep --loop
```

> ğŸ’¡ Use the built-in emote editor in the web dashboard, or preview locally with `python tools/emote_preview.py`

---

## project structure

```
qubit/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.example.yaml
â”‚   â””â”€â”€ config.yaml                  # local config (git-ignored)
â”œâ”€â”€ scripts/                         # runnable scripts
â”‚   â”œâ”€â”€ run_arm.py
â”‚   â”œâ”€â”€ teleop.py
â”‚   â”œâ”€â”€ record_demo.py
â”‚   â”œâ”€â”€ play_demo.py
â”‚   â”œâ”€â”€ calibrate.py
â”‚   â”œâ”€â”€ led_matrix.py
â”‚   â”œâ”€â”€ led_tubes.py
â”‚   â”œâ”€â”€ face_track.py
â”‚   â”œâ”€â”€ idle_behavior.py
â”‚   â”œâ”€â”€ diagnostics.py
â”‚   â””â”€â”€ dashboard.py
â”œâ”€â”€ emotes/                          # LED matrix animations (JSON)
â”‚   â””â”€â”€ *.json
â”œâ”€â”€ stl/                             # 3D printable parts
â”‚   â””â”€â”€ *.stl
â”œâ”€â”€ demos/                           # recorded arm sequences
â”‚   â”œâ”€â”€ wave.json
â”‚   â””â”€â”€ idle_sway.json
â”œâ”€â”€ qubit/                           # core Python library
â”‚   â”œâ”€â”€ arm.py                       # SO-100 arm control
â”‚   â”œâ”€â”€ servo.py                     # STS3215 serial bus driver
â”‚   â”œâ”€â”€ led_matrix.py                # iDotMatrix driver
â”‚   â”œâ”€â”€ led_tubes.py                 # WS2812B driver
â”‚   â”œâ”€â”€ camera.py                    # camera + CV utilities
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ emote_preview.py
â”‚   â””â”€â”€ scan_servos.py
â””â”€â”€ assets/
    â”œâ”€â”€ thumbnail.JPG
    â”œâ”€â”€ pickup_screwdriver.gif
    â””â”€â”€ robot_dance.gif
```

---

## troubleshooting

**servos not responding**
- Check port assignment: `ls /dev/ttyUSB*`
- Verify power supply is 7.4â€“7.5V at 5A+ per arm
- Run `python scripts/diagnostics.py --arm all`
- Scan for servo IDs: `python tools/scan_servos.py`

**LED matrix not connecting**
- Enable Bluetooth: `sudo systemctl enable bluetooth`
- Pair first: `bluetoothctl` â†’ `scan on` â†’ `pair <MAC>`
- Verify MAC in `config.yaml`

**arm moving to wrong position**
- Recalibrate: `python scripts/calibrate.py --arm left`
- Check for mechanical binding (common with first-print tolerances)

**camera / face tracking not working**
- Install OpenCV: `pip install opencv-python-headless`
- Enable camera: `sudo raspi-config` â†’ Interface Options â†’ Camera

**low FPS in teleoperation**
- Lower servo polling: `teleop.hz: 50` in `config.yaml`
- Confirm Python 3.10+ and venv is active

---

## contributing

PRs welcome. For major changes, open an issue first.

```bash
git checkout -b feature/your-idea
# make your changes
git push origin feature/your-idea
# open a PR
```

**Custom emotes especially encouraged** â€” drop your `.json` files in `/emotes` and ship it.

---

<div align="center">

---

built by [**@0xaiwhisperer**](https://twitter.com/0xaiwhisperer)

*The A.I. Whisperer Â· machines, memes, and magic*

</div>